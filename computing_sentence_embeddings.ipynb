{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "computing_sentence_embeddings.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/teamasrmilano/Embeddings/blob/master/computing_sentence_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "OUx7hqXkyz_7"
      },
      "cell_type": "markdown",
      "source": [
        "# Computing sentence embeddings"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "6J3UbpQ3yz_9"
      },
      "cell_type": "markdown",
      "source": [
        "A first prototype on a small corpus, following https://openreview.net/pdf?id=SyK00v5xx.\n",
        "\n",
        "The basic idea is to compute the sentence vector v_s as a weighted average of the word vectors associated with the words contained in s. The weight of each vector is an inverse function of the probability of the corresponding word in the corpus:"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "46XmyxsWyz__"
      },
      "cell_type": "markdown",
      "source": [
        "![s_formula](https://drive.google.com/uc?id=1rbDS6cuPPPm05V-6qEnUzX-PPcCYPP6h)"
      ]
    },
    {
      "metadata": {
        "id": "E4ubYDQ5JQck",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We need the following ingredients:\n",
        "\n",
        "1) a set of sentences (corpus)\n",
        "\n",
        "2) the vocabulary of corpus (unique tokens)\n",
        "\n",
        "3) the probability of each word in the vocabulary (frequency in the corpus)\n",
        "\n",
        "4) a word vector (embedding) for each word"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "0tIOMN4Xy0AA"
      },
      "cell_type": "markdown",
      "source": [
        "Import basic packages first:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "obSL0qBiy0AB",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# basic\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re # regular expressions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "eTq79VMqy0AF"
      },
      "cell_type": "markdown",
      "source": [
        "The parameter a is manually set to 0.001 (see paper):"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "lSzEmX2oy0AH",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a = 0.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "4-_Ed7Czy0AM"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we load our corpus, which is a random sample of 50k sentences from OpenSubtitles corpus available at http://opus.nlpl.eu/OpenSubtitles-v2018.php. The full corpus has been slightly cleaned and the sample obtained with bash command shuf."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Jner1MkMy0AN",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('mini-subtitles-corpus', 'r') as input_file:\n",
        "    corpus = input_file.read()\n",
        "\n",
        "corpus = re.sub('\\n', '. ', corpus) # we'll split sentences based on full stops with spacy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6dG8TtH1y0AR",
        "outputId": "5fc22907-7cea-4108-b374-5d356d2a9c1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(corpus))\n",
        "corpus[0:1000]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2168174\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"ok, beh, apprezzo la tua preoccupazione. avresti dovuto dirle prima queste cose. ti stai divertendo, blaine. sono miei ormai. quando ero a princeton, ho scritto la mia tesi sulle passioni degli stoici. hai una macchia sul tuo file, delinquente. presto anche tu capirai. se non lo fai, lo chiamo e gli dico dove sei. beh, sarebbe stato prima che venissi uccisa, ma funziona anche così. usa la presa al ginocchio. dolore e dai desideri. di che puntualizzazione parli. nella mia fantasia, noi ci trasferiamo nell'attico di jennifer lawrence. mazzola. perché loro non si lavano. non se ne adrà via. ah, 50ooo lire, don pietro. bob e malcolm sono stati licenziati. seq druven begnan si. molti amici mi hanno chiesto di farti ripensare a questa cosa. avrei dovuto lasciarla morire per evitare che lei odiasse me. erano un bersaglio facile mentre stavano dormendo nei loro nidi, di giorno. qual è stato il primo film western a vincere l'oscar come miglior film. magari mi fai vedere l'insegnante di inglese.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "39QOzP81y0AY"
      },
      "cell_type": "markdown",
      "source": [
        "A bunch of sentences, as expected.\n",
        "\n",
        "Next, we parse the corpus with spacy (it'll take a while):"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UcFGYJhmy0AZ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import spaCy for nlp and italian resources (install if necessary)\n",
        "\n",
        "#!pip3 install spacy\n",
        "#!python3 -m spacy download it\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('it')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-qfaUjedy0Ae",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nlp.max_length = 2500000\n",
        "doc = nlp(corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "V7OlTqddy0Aj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentences = [sentence for sentence in doc.sents]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "u398OJc1y0Ap",
        "outputId": "f4c12f79-6ae9-426e-b2b9-2c6bc04c99c2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentences[0:9]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ok, beh, apprezzo la tua preoccupazione.,\n",
              " avresti dovuto dirle prima queste cose.,\n",
              " ti stai divertendo, blaine.,\n",
              " sono miei ormai.,\n",
              " quando ero a princeton, ho scritto la mia tesi sulle passioni degli stoici.,\n",
              " hai una macchia sul tuo file, delinquente.,\n",
              " presto anche tu capirai.,\n",
              " se non lo fai, lo chiamo e gli dico dove sei.,\n",
              " beh, sarebbe stato prima che venissi uccisa, ma funziona anche così.]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Gf8vVhd3y0Ay",
        "outputId": "25998791-73df-4bdc-f21e-89dd1ccc0ff2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "len(sentences)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49669"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "67cAfjo4y0A7"
      },
      "cell_type": "markdown",
      "source": [
        "Get tokens, stripping punctuation:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JOA6yS2ly0A8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokens = [token.text for token in doc if token.is_punct != True]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wo8SDblgy0BB",
        "outputId": "74d2e627-36c3-4a49-e107-7c2fb0ba3467",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "len(tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "375400"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "4WLqYEkcy0BO"
      },
      "cell_type": "markdown",
      "source": [
        "Get frequency of each token:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "j-BEcvfVy0BP",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# we use Counter from collections package\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "I5Lksm7Dy0BS",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokens_count = Counter(tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "2E6ZwF9Dy0BZ"
      },
      "cell_type": "markdown",
      "source": [
        "For example:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "rponPUpzy0Bc",
        "outputId": "0480a0a7-3dac-4237-c18c-8536e90ae3a1",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokens_count.most_common(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('di', 9946),\n",
              " ('che', 9785),\n",
              " ('non', 8535),\n",
              " ('è', 8055),\n",
              " ('e', 6578),\n",
              " ('la', 6408),\n",
              " ('il', 6134),\n",
              " ('un', 5647),\n",
              " ('a', 5643),\n",
              " ('per', 4860)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gqVNbOdTy0Bj",
        "outputId": "06c530fa-b006-4572-bb24-145c2196998c",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokens_count['cane']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "XtCFVK31y0Bo"
      },
      "cell_type": "markdown",
      "source": [
        "Get list of unique tokens:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "oiY-X-7Sy0Bq",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unique_tokens = set(tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ziM86WrFy0B7",
        "outputId": "49fcddd0-2912-46fd-bf3f-2e6a371292bf",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocab_size = len(unique_tokens)\n",
        "print(vocab_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34870\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Rqob79AHy0CD"
      },
      "cell_type": "markdown",
      "source": [
        "With this list we can put together a dictionary of unique tokens with their probability in the corpus:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "hh31H3nuy0CF",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# iterating on the keys of tokens_count object, we divide the count of each token by the length of the vocabulary\n",
        "tokens_prob = {key : tokens_count[key]/vocab_size for key in tokens_count.keys()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "uHOdNniJy0CJ"
      },
      "cell_type": "markdown",
      "source": [
        "For example:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KG8bfPUry0CK",
        "outputId": "e402fab0-8c57-4748-a9c1-0feec122afad",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokens_prob['il']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.17591052480642386"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "nFZ-f74iy0CO",
        "outputId": "e24ab820-376d-4df3-f94f-3c38b71a54bc",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokens_prob['cane']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0012331517063378262"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-D_xd8MEy0CV",
        "outputId": "5bfab9e5-275f-459f-b79e-a950f44b23f7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokens_prob['segugio']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.8677946659019214e-05"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Tf8Vpm1Ey0Cr"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we train Word2Vec model on our corpus with gensim:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0kpI1RRQy0Cs",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# gensim is used to load word embeddings (install if necessary)\n",
        "\n",
        "#!pip3 install gensim\n",
        "\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VyJuPzyqy0Cv"
      },
      "cell_type": "markdown",
      "source": [
        "We need tokenized sentences as input for Word2Vec:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "AvKCrsVTy0C1",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# double list comprehension: collect tokens, stripping punctuation, for each sentence in doc\n",
        "tokenized_sentences = [[token.text for token in sentence if token.is_punct != True] for sentence in sentences]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "KWBROawzy0C4"
      },
      "cell_type": "markdown",
      "source": [
        "For example:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bcWVwdDCy0C6",
        "outputId": "7fbf4ff6-b1a2-47e1-fd2d-df399551fa5f",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokenized_sentences[0:9]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['ok', 'beh', 'apprezzo', 'la', 'tua', 'preoccupazione'],\n",
              " ['avresti', 'dovuto', 'dirle', 'prima', 'queste', 'cose'],\n",
              " ['ti', 'stai', 'divertendo', 'blaine'],\n",
              " ['sono', 'miei', 'ormai'],\n",
              " ['quando',\n",
              "  'ero',\n",
              "  'a',\n",
              "  'princeton',\n",
              "  'ho',\n",
              "  'scritto',\n",
              "  'la',\n",
              "  'mia',\n",
              "  'tesi',\n",
              "  'sulle',\n",
              "  'passioni',\n",
              "  'degli',\n",
              "  'stoici'],\n",
              " ['hai', 'una', 'macchia', 'sul', 'tuo', 'file', 'delinquente'],\n",
              " ['presto', 'anche', 'tu', 'capirai'],\n",
              " ['se', 'non', 'lo', 'fai', 'lo', 'chiamo', 'e', 'gli', 'dico', 'dove', 'sei'],\n",
              " ['beh',\n",
              "  'sarebbe',\n",
              "  'stato',\n",
              "  'prima',\n",
              "  'che',\n",
              "  'venissi',\n",
              "  'uccisa',\n",
              "  'ma',\n",
              "  'funziona',\n",
              "  'anche',\n",
              "  'così']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9hZYiFNmy0DJ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vec_size = int(vocab_size ** 0.25) # rule of thumb to decide size of embedding vectors\n",
        "model = Word2Vec(tokenized_sentences, size=vec_size, window=5, min_count=1, workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "78hYuqBny0DN"
      },
      "cell_type": "markdown",
      "source": [
        "For example:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Geg9bA3Xy0DO",
        "outputId": "54a28408-0137-4695-c160-8cd0c3bb37b2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.wv['cane'] # show only the first nine values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.01952695, -0.86842334, -0.22365926,  0.5114697 ,  0.14627382,\n",
              "        0.19584416,  0.09706935, -0.3976206 , -0.7282566 ,  0.3901895 ,\n",
              "       -0.8380402 , -0.11870573, -0.14886639], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "rtLFe5gey0Dd",
        "outputId": "8d1d14ba-976c-4aa3-8b41-a2a68a8ecdf3",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.wv['lupo'][0:9] # show only the first nine values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.03319192, -0.32517394,  0.01581433,  0.24791561,  0.14155361,\n",
              "        0.05693622,  0.08089875, -0.26927668, -0.36346108], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "krEiN5e-y0Du",
        "outputId": "7b494d24-376c-439d-903c-261a442bebfe",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.wv['gatto'][0:9] # show only the first nine values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.02101748, -0.23991947, -0.01404044,  0.15411705,  0.11981014,\n",
              "        0.10202154,  0.14525932, -0.23332986, -0.30248007], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "fXtGxPFby0Dy"
      },
      "cell_type": "markdown",
      "source": [
        "Double check vocabulary:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Fz9NtLsay0D2",
        "outputId": "675fb7e2-88cf-46dd-c21d-6e8bd440e121",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_unique_tokens = set([token for token in model.wv.vocab]) # unique tokens in model vocab\n",
        "model_unique_tokens == set(unique_tokens) # exaclty the same as unique_tokens above?"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "FkXJ5MAHy0D9"
      },
      "cell_type": "markdown",
      "source": [
        "Cool.\n",
        "\n",
        "We have all our ingredients: sentences, tokens, probabilities and vectors.\n",
        "\n",
        "Let's move to sentence embedding algorithm:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "BZoMoPUTy0D-",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def compute_s_vec(sentence, a=0.001): # make sure sentence is tokenized! \n",
        "\n",
        "    sent_vec = np.zeros(shape=vec_size) # initialize vector of zeros with the wanted shape\n",
        "\n",
        "    for token in sentence: # cycle through tokens in sentence\n",
        "        token_p = tokens_prob[token] # probability of token\n",
        "        token_vec = model.wv[token] # token vector\n",
        "        weighted_token_vec = token_vec*(a/(a+token_p)) # weighted vector of token\n",
        "        sent_vec = sent_vec + weighted_token_vec # sum\n",
        "\n",
        "    sent_vec = sent_vec*(1/len(sent_vec)) # average\n",
        "\n",
        "    return(sent_vec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Job1Gpp1y0EB"
      },
      "cell_type": "markdown",
      "source": [
        "For example:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9FLNaAhNy0EC",
        "outputId": "e79fabce-28d9-4438-8b79-7aacb5383d61",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "il_cane_lupo = compute_s_vec(['il', 'cane', 'lupo'])\n",
        "il_cane_lupo[0:9]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.00170747, -0.04825916, -0.0072154 ,  0.03150852,  0.01119856,\n",
              "        0.01035368,  0.00720739, -0.02771687, -0.04392113])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "HkUZ8_jRy0EH",
        "outputId": "96cf3e6e-914a-4fbe-a507-82e1f1ac96c2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "il_cane_gatto = compute_s_vec(['il', 'cane', 'gatto'])\n",
        "il_cane_gatto[0:9]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.00119312, -0.04501374, -0.00872881,  0.02751561,  0.01059617,\n",
              "        0.01294983,  0.010912  , -0.02685651, -0.04210279])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "_a1TTS11y0EM"
      },
      "cell_type": "markdown",
      "source": [
        "Finally, create a dictionary computing vector for each sentence in corpus:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UGPAfSPLy0EN",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sent_vectors = {\" \".join(tokenized_sentences[i]) : compute_s_vec(tokenized_sentences[i]) for i in range(len(sentences))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jfIKbXm4JQev",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Make a dataframe where columns are word vectors:"
      ]
    },
    {
      "metadata": {
        "id": "0e9HW5w8JQex",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sent_vec_df = pd.DataFrame.from_dict(sent_vectors, orient='columns')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iCNtUsn8JQez",
        "colab_type": "code",
        "outputId": "9a5160f1-6a5c-484b-a7a1-530173dbed21",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sent_vec_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>1 0</th>\n",
              "      <th>1 00 miglia a est di tulip</th>\n",
              "      <th>1 4 aprile ore 2030</th>\n",
              "      <th>1 749 poco prima dell' orario di chiusura</th>\n",
              "      <th>14 placcato da una ragazza</th>\n",
              "      <th>14 settembre 1988</th>\n",
              "      <th>17 chiamami jeon jin ho</th>\n",
              "      <th>1x04 the pretender</th>\n",
              "      <th>3x08 all' the wisdom i got left</th>\n",
              "      <th>...</th>\n",
              "      <th>è vile e disgustosa</th>\n",
              "      <th>è vincolante</th>\n",
              "      <th>è viva e se la spassa a coral gables</th>\n",
              "      <th>è vivo ed è tornato vincitore</th>\n",
              "      <th>è volato via da uno dei piloni</th>\n",
              "      <th>è vuoto da parecchio tempo</th>\n",
              "      <th>è zane cannon</th>\n",
              "      <th>èmolto probabile che consiste di anidride carbonica</th>\n",
              "      <th>èrustico</th>\n",
              "      <th>èstato colpito alla testa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004612</td>\n",
              "      <td>0.013016</td>\n",
              "      <td>0.003639</td>\n",
              "      <td>0.009370</td>\n",
              "      <td>0.019924</td>\n",
              "      <td>0.006273</td>\n",
              "      <td>0.013148</td>\n",
              "      <td>0.008094</td>\n",
              "      <td>0.003100</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001817</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.020640</td>\n",
              "      <td>0.022562</td>\n",
              "      <td>0.005764</td>\n",
              "      <td>0.014449</td>\n",
              "      <td>-0.004111</td>\n",
              "      <td>0.010064</td>\n",
              "      <td>-0.002154</td>\n",
              "      <td>0.010237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.070560</td>\n",
              "      <td>-0.134504</td>\n",
              "      <td>-0.161405</td>\n",
              "      <td>-0.151702</td>\n",
              "      <td>-0.079950</td>\n",
              "      <td>-0.072541</td>\n",
              "      <td>-0.067501</td>\n",
              "      <td>-0.075093</td>\n",
              "      <td>-0.131364</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.013355</td>\n",
              "      <td>0.001118</td>\n",
              "      <td>-0.040606</td>\n",
              "      <td>-0.100824</td>\n",
              "      <td>-0.082532</td>\n",
              "      <td>-0.072323</td>\n",
              "      <td>-0.002631</td>\n",
              "      <td>-0.046918</td>\n",
              "      <td>-0.001474</td>\n",
              "      <td>-0.082077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.020033</td>\n",
              "      <td>-0.030459</td>\n",
              "      <td>-0.035128</td>\n",
              "      <td>-0.037432</td>\n",
              "      <td>-0.017476</td>\n",
              "      <td>-0.014038</td>\n",
              "      <td>-0.014991</td>\n",
              "      <td>-0.020494</td>\n",
              "      <td>-0.035421</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.005095</td>\n",
              "      <td>-0.002281</td>\n",
              "      <td>-0.006729</td>\n",
              "      <td>0.005096</td>\n",
              "      <td>-0.002382</td>\n",
              "      <td>-0.001981</td>\n",
              "      <td>-0.004906</td>\n",
              "      <td>-0.001525</td>\n",
              "      <td>0.001243</td>\n",
              "      <td>-0.020940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.028402</td>\n",
              "      <td>0.062861</td>\n",
              "      <td>0.077565</td>\n",
              "      <td>0.066441</td>\n",
              "      <td>0.028200</td>\n",
              "      <td>0.030413</td>\n",
              "      <td>0.032750</td>\n",
              "      <td>0.042396</td>\n",
              "      <td>0.063013</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001841</td>\n",
              "      <td>0.002872</td>\n",
              "      <td>0.016839</td>\n",
              "      <td>0.051775</td>\n",
              "      <td>0.022791</td>\n",
              "      <td>0.038079</td>\n",
              "      <td>-0.002188</td>\n",
              "      <td>0.015255</td>\n",
              "      <td>0.000192</td>\n",
              "      <td>0.020424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.027282</td>\n",
              "      <td>0.047942</td>\n",
              "      <td>0.057292</td>\n",
              "      <td>0.052051</td>\n",
              "      <td>0.029038</td>\n",
              "      <td>0.030188</td>\n",
              "      <td>0.022540</td>\n",
              "      <td>0.027206</td>\n",
              "      <td>0.051764</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001395</td>\n",
              "      <td>-0.000581</td>\n",
              "      <td>0.022016</td>\n",
              "      <td>0.029011</td>\n",
              "      <td>0.033898</td>\n",
              "      <td>0.020532</td>\n",
              "      <td>-0.003554</td>\n",
              "      <td>0.020382</td>\n",
              "      <td>-0.002646</td>\n",
              "      <td>0.021693</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 49666 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             1 0  1 00 miglia a est di tulip  1 4 aprile ore 2030  \\\n",
              "0  0.0  0.004612                    0.013016             0.003639   \n",
              "1  0.0 -0.070560                   -0.134504            -0.161405   \n",
              "2  0.0 -0.020033                   -0.030459            -0.035128   \n",
              "3  0.0  0.028402                    0.062861             0.077565   \n",
              "4  0.0  0.027282                    0.047942             0.057292   \n",
              "\n",
              "   1 749 poco prima dell' orario di chiusura  14 placcato da una ragazza  \\\n",
              "0                                   0.009370                    0.019924   \n",
              "1                                  -0.151702                   -0.079950   \n",
              "2                                  -0.037432                   -0.017476   \n",
              "3                                   0.066441                    0.028200   \n",
              "4                                   0.052051                    0.029038   \n",
              "\n",
              "   14 settembre 1988  17 chiamami jeon jin ho  1x04 the pretender  \\\n",
              "0           0.006273                 0.013148            0.008094   \n",
              "1          -0.072541                -0.067501           -0.075093   \n",
              "2          -0.014038                -0.014991           -0.020494   \n",
              "3           0.030413                 0.032750            0.042396   \n",
              "4           0.030188                 0.022540            0.027206   \n",
              "\n",
              "   3x08 all' the wisdom i got left  ...  è vile e disgustosa  è vincolante  \\\n",
              "0                         0.003100  ...             0.001817      0.000004   \n",
              "1                        -0.131364  ...            -0.013355      0.001118   \n",
              "2                        -0.035421  ...            -0.005095     -0.002281   \n",
              "3                         0.063013  ...             0.001841      0.002872   \n",
              "4                         0.051764  ...             0.001395     -0.000581   \n",
              "\n",
              "   è viva e se la spassa a coral gables  è vivo ed è tornato vincitore  \\\n",
              "0                              0.020640                       0.022562   \n",
              "1                             -0.040606                      -0.100824   \n",
              "2                             -0.006729                       0.005096   \n",
              "3                              0.016839                       0.051775   \n",
              "4                              0.022016                       0.029011   \n",
              "\n",
              "   è volato via da uno dei piloni  è vuoto da parecchio tempo  è zane cannon  \\\n",
              "0                        0.005764                    0.014449      -0.004111   \n",
              "1                       -0.082532                   -0.072323      -0.002631   \n",
              "2                       -0.002382                   -0.001981      -0.004906   \n",
              "3                        0.022791                    0.038079      -0.002188   \n",
              "4                        0.033898                    0.020532      -0.003554   \n",
              "\n",
              "   èmolto probabile che consiste di anidride carbonica  èrustico  \\\n",
              "0                                           0.010064   -0.002154   \n",
              "1                                          -0.046918   -0.001474   \n",
              "2                                          -0.001525    0.001243   \n",
              "3                                           0.015255    0.000192   \n",
              "4                                           0.020382   -0.002646   \n",
              "\n",
              "   èstato colpito alla testa  \n",
              "0                   0.010237  \n",
              "1                  -0.082077  \n",
              "2                  -0.020940  \n",
              "3                   0.020424  \n",
              "4                   0.021693  \n",
              "\n",
              "[5 rows x 49666 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "uavvs65UJQe2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can drop first two columns:"
      ]
    },
    {
      "metadata": {
        "id": "erYt8CR5JQe2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sent_vec_df = sent_vec_df.drop(columns = ['','1 0'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i27sRKLhJQe4",
        "colab_type": "code",
        "outputId": "de45879b-0831-44cc-d18b-2555f0feb786",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sent_vec_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1 00 miglia a est di tulip</th>\n",
              "      <th>1 4 aprile ore 2030</th>\n",
              "      <th>1 749 poco prima dell' orario di chiusura</th>\n",
              "      <th>14 placcato da una ragazza</th>\n",
              "      <th>14 settembre 1988</th>\n",
              "      <th>17 chiamami jeon jin ho</th>\n",
              "      <th>1x04 the pretender</th>\n",
              "      <th>3x08 all' the wisdom i got left</th>\n",
              "      <th>7 minuti</th>\n",
              "      <th>9 future tense</th>\n",
              "      <th>...</th>\n",
              "      <th>è vile e disgustosa</th>\n",
              "      <th>è vincolante</th>\n",
              "      <th>è viva e se la spassa a coral gables</th>\n",
              "      <th>è vivo ed è tornato vincitore</th>\n",
              "      <th>è volato via da uno dei piloni</th>\n",
              "      <th>è vuoto da parecchio tempo</th>\n",
              "      <th>è zane cannon</th>\n",
              "      <th>èmolto probabile che consiste di anidride carbonica</th>\n",
              "      <th>èrustico</th>\n",
              "      <th>èstato colpito alla testa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.013016</td>\n",
              "      <td>0.003639</td>\n",
              "      <td>0.009370</td>\n",
              "      <td>0.019924</td>\n",
              "      <td>0.006273</td>\n",
              "      <td>0.013148</td>\n",
              "      <td>0.008094</td>\n",
              "      <td>0.003100</td>\n",
              "      <td>0.006417</td>\n",
              "      <td>0.007273</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001817</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.020640</td>\n",
              "      <td>0.022562</td>\n",
              "      <td>0.005764</td>\n",
              "      <td>0.014449</td>\n",
              "      <td>-0.004111</td>\n",
              "      <td>0.010064</td>\n",
              "      <td>-0.002154</td>\n",
              "      <td>0.010237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.134504</td>\n",
              "      <td>-0.161405</td>\n",
              "      <td>-0.151702</td>\n",
              "      <td>-0.079950</td>\n",
              "      <td>-0.072541</td>\n",
              "      <td>-0.067501</td>\n",
              "      <td>-0.075093</td>\n",
              "      <td>-0.131364</td>\n",
              "      <td>-0.072833</td>\n",
              "      <td>-0.046621</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.013355</td>\n",
              "      <td>0.001118</td>\n",
              "      <td>-0.040606</td>\n",
              "      <td>-0.100824</td>\n",
              "      <td>-0.082532</td>\n",
              "      <td>-0.072323</td>\n",
              "      <td>-0.002631</td>\n",
              "      <td>-0.046918</td>\n",
              "      <td>-0.001474</td>\n",
              "      <td>-0.082077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.030459</td>\n",
              "      <td>-0.035128</td>\n",
              "      <td>-0.037432</td>\n",
              "      <td>-0.017476</td>\n",
              "      <td>-0.014038</td>\n",
              "      <td>-0.014991</td>\n",
              "      <td>-0.020494</td>\n",
              "      <td>-0.035421</td>\n",
              "      <td>-0.010374</td>\n",
              "      <td>-0.006055</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.005095</td>\n",
              "      <td>-0.002281</td>\n",
              "      <td>-0.006729</td>\n",
              "      <td>0.005096</td>\n",
              "      <td>-0.002382</td>\n",
              "      <td>-0.001981</td>\n",
              "      <td>-0.004906</td>\n",
              "      <td>-0.001525</td>\n",
              "      <td>0.001243</td>\n",
              "      <td>-0.020940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.062861</td>\n",
              "      <td>0.077565</td>\n",
              "      <td>0.066441</td>\n",
              "      <td>0.028200</td>\n",
              "      <td>0.030413</td>\n",
              "      <td>0.032750</td>\n",
              "      <td>0.042396</td>\n",
              "      <td>0.063013</td>\n",
              "      <td>0.037878</td>\n",
              "      <td>0.026234</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001841</td>\n",
              "      <td>0.002872</td>\n",
              "      <td>0.016839</td>\n",
              "      <td>0.051775</td>\n",
              "      <td>0.022791</td>\n",
              "      <td>0.038079</td>\n",
              "      <td>-0.002188</td>\n",
              "      <td>0.015255</td>\n",
              "      <td>0.000192</td>\n",
              "      <td>0.020424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.047942</td>\n",
              "      <td>0.057292</td>\n",
              "      <td>0.052051</td>\n",
              "      <td>0.029038</td>\n",
              "      <td>0.030188</td>\n",
              "      <td>0.022540</td>\n",
              "      <td>0.027206</td>\n",
              "      <td>0.051764</td>\n",
              "      <td>0.029619</td>\n",
              "      <td>0.021295</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001395</td>\n",
              "      <td>-0.000581</td>\n",
              "      <td>0.022016</td>\n",
              "      <td>0.029011</td>\n",
              "      <td>0.033898</td>\n",
              "      <td>0.020532</td>\n",
              "      <td>-0.003554</td>\n",
              "      <td>0.020382</td>\n",
              "      <td>-0.002646</td>\n",
              "      <td>0.021693</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 49664 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   1 00 miglia a est di tulip  1 4 aprile ore 2030  \\\n",
              "0                    0.013016             0.003639   \n",
              "1                   -0.134504            -0.161405   \n",
              "2                   -0.030459            -0.035128   \n",
              "3                    0.062861             0.077565   \n",
              "4                    0.047942             0.057292   \n",
              "\n",
              "   1 749 poco prima dell' orario di chiusura  14 placcato da una ragazza  \\\n",
              "0                                   0.009370                    0.019924   \n",
              "1                                  -0.151702                   -0.079950   \n",
              "2                                  -0.037432                   -0.017476   \n",
              "3                                   0.066441                    0.028200   \n",
              "4                                   0.052051                    0.029038   \n",
              "\n",
              "   14 settembre 1988  17 chiamami jeon jin ho  1x04 the pretender  \\\n",
              "0           0.006273                 0.013148            0.008094   \n",
              "1          -0.072541                -0.067501           -0.075093   \n",
              "2          -0.014038                -0.014991           -0.020494   \n",
              "3           0.030413                 0.032750            0.042396   \n",
              "4           0.030188                 0.022540            0.027206   \n",
              "\n",
              "   3x08 all' the wisdom i got left  7 minuti  9 future tense  ...  \\\n",
              "0                         0.003100  0.006417        0.007273  ...   \n",
              "1                        -0.131364 -0.072833       -0.046621  ...   \n",
              "2                        -0.035421 -0.010374       -0.006055  ...   \n",
              "3                         0.063013  0.037878        0.026234  ...   \n",
              "4                         0.051764  0.029619        0.021295  ...   \n",
              "\n",
              "   è vile e disgustosa  è vincolante  è viva e se la spassa a coral gables  \\\n",
              "0             0.001817      0.000004                              0.020640   \n",
              "1            -0.013355      0.001118                             -0.040606   \n",
              "2            -0.005095     -0.002281                             -0.006729   \n",
              "3             0.001841      0.002872                              0.016839   \n",
              "4             0.001395     -0.000581                              0.022016   \n",
              "\n",
              "   è vivo ed è tornato vincitore  è volato via da uno dei piloni  \\\n",
              "0                       0.022562                        0.005764   \n",
              "1                      -0.100824                       -0.082532   \n",
              "2                       0.005096                       -0.002382   \n",
              "3                       0.051775                        0.022791   \n",
              "4                       0.029011                        0.033898   \n",
              "\n",
              "   è vuoto da parecchio tempo  è zane cannon  \\\n",
              "0                    0.014449      -0.004111   \n",
              "1                   -0.072323      -0.002631   \n",
              "2                   -0.001981      -0.004906   \n",
              "3                    0.038079      -0.002188   \n",
              "4                    0.020532      -0.003554   \n",
              "\n",
              "   èmolto probabile che consiste di anidride carbonica  èrustico  \\\n",
              "0                                           0.010064   -0.002154   \n",
              "1                                          -0.046918   -0.001474   \n",
              "2                                          -0.001525    0.001243   \n",
              "3                                           0.015255    0.000192   \n",
              "4                                           0.020382   -0.002646   \n",
              "\n",
              "   èstato colpito alla testa  \n",
              "0                   0.010237  \n",
              "1                  -0.082077  \n",
              "2                  -0.020940  \n",
              "3                   0.020424  \n",
              "4                   0.021693  \n",
              "\n",
              "[5 rows x 49664 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "gxECtPjnJQe8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#sent_vec_df.to_csv(\"sentence_vectors.tsv\", sep='\\t', index=False, index_label=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TWy2KYUPJQfA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As matrix:"
      ]
    },
    {
      "metadata": {
        "id": "YrUNF-lPJQfB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sent_vec_matrix = sent_vec_df.to_numpy() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oZRt20uvJQfE",
        "colab_type": "code",
        "outputId": "0d733904-f25f-410e-9470-720088beff5c",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sent_vec_matrix.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13, 49664)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "OiZUgWmRJQfI",
        "colab_type": "code",
        "outputId": "a1d7da7d-2284-4f32-9309-dbc3468553fd",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sent_vec_matrix[:,0:9]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.01301633,  0.0036387 ,  0.00936968,  0.01992386,  0.00627333,\n",
              "         0.01314799,  0.00809409,  0.00309993,  0.0064167 ],\n",
              "       [-0.13450362, -0.16140485, -0.15170162, -0.07994987, -0.07254116,\n",
              "        -0.0675015 , -0.07509253, -0.13136393, -0.07283299],\n",
              "       [-0.03045868, -0.035128  , -0.03743216, -0.01747611, -0.01403762,\n",
              "        -0.01499107, -0.02049371, -0.03542052, -0.01037356],\n",
              "       [ 0.06286137,  0.07756484,  0.06644113,  0.02820012,  0.0304128 ,\n",
              "         0.03275006,  0.04239554,  0.06301266,  0.03787784],\n",
              "       [ 0.04794178,  0.05729186,  0.05205051,  0.02903815,  0.03018784,\n",
              "         0.02254012,  0.02720561,  0.05176378,  0.02961893],\n",
              "       [ 0.03973577,  0.05337564,  0.05080131,  0.02001939,  0.0189963 ,\n",
              "         0.0219002 ,  0.02693642,  0.04425231,  0.02712512],\n",
              "       [-0.02029607, -0.02738428, -0.01452657,  0.00192814, -0.00982968,\n",
              "        -0.00623123, -0.01644851, -0.03353185, -0.01154771],\n",
              "       [-0.01418074, -0.01596084, -0.02179708, -0.01198874, -0.01285584,\n",
              "        -0.01889056, -0.0043233 , -0.00648577, -0.00764722],\n",
              "       [-0.09814705, -0.11575964, -0.11400784, -0.06375149, -0.05298344,\n",
              "        -0.06072592, -0.05570241, -0.09580645, -0.05886015],\n",
              "       [ 0.0483602 ,  0.05454379,  0.05685263,  0.03755477,  0.03011292,\n",
              "         0.02416362,  0.02635581,  0.04742638,  0.02499015],\n",
              "       [-0.09875936, -0.11945628, -0.12461132, -0.06449846, -0.05641297,\n",
              "        -0.06313436, -0.05382324, -0.09263796, -0.05686529],\n",
              "       [-0.00020555, -0.0050174 , -0.00159941,  0.00369931, -0.00592154,\n",
              "        -0.00830262, -0.00396342,  0.0002042 , -0.00341358],\n",
              "       [-0.01955815, -0.02562412, -0.01232293,  0.00313283, -0.01685618,\n",
              "        -0.02116397, -0.01570723, -0.03448351, -0.0133475 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "oHnw-Pe1JQfM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Extract first singular vector of the matrix, using svd from scikit-learn:"
      ]
    },
    {
      "metadata": {
        "id": "U8HY_M_1JQfN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.utils.extmath import randomized_svd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ShRYt5QRJQfR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "U, S, vt = randomized_svd(sent_vec_matrix, n_components=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "pLWUmZJKJQfU",
        "colab_type": "code",
        "outputId": "dc36b698-0167-4fb5-e459-6be1e86d72d1",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "U"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.14388128],\n",
              "       [ 0.53930292],\n",
              "       [ 0.10229087],\n",
              "       [-0.21976348],\n",
              "       [-0.21930481],\n",
              "       [-0.16118187],\n",
              "       [ 0.00646664],\n",
              "       [ 0.16959303],\n",
              "       [ 0.49321712],\n",
              "       [-0.20826905],\n",
              "       [ 0.47713661],\n",
              "       [ 0.04614985],\n",
              "       [ 0.10190706]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "k6-nzoenJQfW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "From U to UUT:"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QOneGCCQJQfY",
        "colab_type": "code",
        "outputId": "7d5f91ab-4653-4bcb-9c7b-93db2bcad8c1",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "UUT = np.outer(U,U.T)\n",
        "UUT.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "metadata": {
        "id": "vLmImiFiJQfb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's look at one example:"
      ]
    },
    {
      "metadata": {
        "id": "FXD9HAaEJQfc",
        "colab_type": "code",
        "outputId": "7a7ecc37-3c46-4ea3-fd6d-dccd9f9621ca",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sent_vec_df['7 minuti']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     0.006417\n",
              "1    -0.072833\n",
              "2    -0.010374\n",
              "3     0.037878\n",
              "4     0.029619\n",
              "5     0.027125\n",
              "6    -0.011548\n",
              "7    -0.007647\n",
              "8    -0.058860\n",
              "9     0.024990\n",
              "10   -0.056865\n",
              "11   -0.003414\n",
              "12   -0.013347\n",
              "Name: 7 minuti, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "6g8UT7rHJQfe",
        "colab_type": "code",
        "outputId": "820059a9-1f1b-4d56-aa1a-9e13b461ca59",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.dot(UUT, sent_vec_df['7 minuti'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.01794381, -0.06725786, -0.01275696,  0.02740727,  0.02735007,\n",
              "        0.02010141, -0.00080647, -0.02115038, -0.06151038,  0.02597377,\n",
              "       -0.05950494, -0.00575547, -0.01270909])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "metadata": {
        "id": "0kK-TTuxJQfi",
        "colab_type": "code",
        "outputId": "885aa11e-f6db-4ac7-b4f4-696ded73af9f",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sent_vec_df['7 minuti'] - np.dot(UUT, sent_vec_df['7 minuti'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.5/dist-packages/pandas/core/computation/check.py:19: UserWarning: The installed version of numexpr 2.4.3 is not supported in pandas and will be not be used\n",
            "The minimum supported version is 2.6.1\n",
            "\n",
            "  ver=ver, min_ver=_MIN_NUMEXPR_VERSION), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    -0.011527\n",
              "1    -0.005575\n",
              "2     0.002383\n",
              "3     0.010471\n",
              "4     0.002269\n",
              "5     0.007024\n",
              "6    -0.010741\n",
              "7     0.013503\n",
              "8     0.002650\n",
              "9    -0.000984\n",
              "10    0.002640\n",
              "11    0.002342\n",
              "12   -0.000638\n",
              "Name: 7 minuti, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "GPXABplfJQfl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Apply this to whole dataset:"
      ]
    },
    {
      "metadata": {
        "id": "kEa7RZqbJQfm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(sent_vec_df.shape[1]):\n",
        "    sent_vec_df.iloc[:,i] = sent_vec_df.iloc[:,i] - np.dot(UUT, sent_vec_df.iloc[:,i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vG2PyhFoJQfo",
        "colab_type": "code",
        "outputId": "832c6400-8507-4a40-8f19-5bddd5080fff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "cell_type": "code",
      "source": [
        "sent_vec_df.iloc[:,0:9]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-19cd1e8edbbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msent_vec_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'sent_vec_df' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "tzUAvFTQJQfr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Save to disk:"
      ]
    },
    {
      "metadata": {
        "id": "ngIwgjSsJQfr",
        "colab_type": "code",
        "outputId": "54ef6ba8-78fc-47ca-d2f5-c57d0b793b0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "cell_type": "code",
      "source": [
        "sent_vec_df.to_csv(\"sentence_embeddings.tsv\", sep=\"\\t\", index=False, index_label=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-bd8e5b2308d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msent_vec_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sentence_embeddings.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'sent_vec_df' is not defined"
          ]
        }
      ]
    }
  ]
}